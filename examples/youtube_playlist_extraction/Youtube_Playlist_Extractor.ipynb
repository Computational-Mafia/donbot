{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zDjhdUxwTz3"
      },
      "source": [
        "# YouTube Playlist Extractor\n",
        "\n",
        "A lot of threads on mafiascum.net contain links to YouTube videos distributed across multiple posts. Particularly when they share the same purpose or theme, it can be useful to extract these links and compile them into a single playlist for easy viewing or listening.\n",
        "\n",
        "This example demonstrates how to use functions from the [donbot](https://github.com/Computational-Mafia/donbot) module to extract YouTube video links across a thread and compile them into a playlist. By changing the thread URL parameter and maybe adding your account credentials, you can use this example to extract a playlist from any thread on the forum.\n",
        "\n",
        "The implementation here has so far been validated to work for threads with ~40 songs. It won't work for threads that require user privileges to access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8QGiRSQu21v",
        "outputId": "5a210015-bea9-4caf-a4a4-912b7d03d0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playlist URL:\n",
            "http://www.youtube.com/watch_videos?video_ids=E0jrUBRlAvA,z87nhzCdYEU,0QaefDV7cb8,QApcyPKEwXI,D9o_XTzYoa8,Epj5A84mDp0,LILIDv0JzEM,9b25Balcsj4,seok6lO1n-8,bLaSOG3Vjbo,qlcfgoTRtUQ,RZxK1kDO7K8,b_CpWmkhwq0,3WpdCZC9q6w,E91pJYO_s7I,PEeRO4k40pM,zdU0qwZKLfU,3zb9X_unuqo,Qss4rfv7n88,n87C0iUyrCU,0ckoUgA7UZQ,iKBCVZqqooY,PVVK7HkdW9k,ekU1dQjMsOQ,NRiOvSqn8aw,xFlULnKuxtg,FnjjbqMjVe4,F9oCB6Rsnqg,fj1RPTj-188,tIxLU8WUK1Y,UtfkrGRK8wA,VYW4F5q7XBE,ds18Ozzp8h0,VC_jqzx4QXc,tGVRsIDNuKU,h2kUX_Fmj7k,3uZ9i4QYRLo,OMFAhvcPLrU,rTcF-tZwlXI,ji6wHH0Gf9I,VS6ixn2berk,E0jrUBRlAvA,z87nhzCdYEU,0QaefDV7cb8,QApcyPKEwXI,D9o_XTzYoa8,Epj5A84mDp0,LILIDv0JzEM,9b25Balcsj4,seok6lO1n-8,bLaSOG3Vjbo,qlcfgoTRtUQ,RZxK1kDO7K8,b_CpWmkhwq0,3WpdCZC9q6w,E91pJYO_s7I,PEeRO4k40pM,zdU0qwZKLfU,3zb9X_unuqo,Qss4rfv7n88,n87C0iUyrCU,0ckoUgA7UZQ,iKBCVZqqooY,PVVK7HkdW9k,ekU1dQjMsOQ,NRiOvSqn8aw,xFlULnKuxtg,FnjjbqMjVe4,F9oCB6Rsnqg,fj1RPTj-188,tIxLU8WUK1Y,UtfkrGRK8wA,VYW4F5q7XBE,ds18Ozzp8h0,VC_jqzx4QXc,tGVRsIDNuKU,h2kUX_Fmj7k,3uZ9i4QYRLo,OMFAhvcPLrU,rTcF-tZwlXI,ji6wHH0Gf9I,VS6ixn2berk\n"
          ]
        }
      ],
      "source": [
        "# @markdown ## Provide a thread url and playlist type. Press the play button the left to generate!\n",
        "thread = \"https://forum.mafiascum.net/viewtopic.php?t=92087\" # @param {type:\"string\"}\n",
        "playlist_type = \"music\" # @param [\"music\", \"regular videos\"]\n",
        "\n",
        "import requests\n",
        "from lxml import html\n",
        "from math import floor\n",
        "\n",
        "def count_posts(session: requests.Session, thread: str) -> int:\n",
        "    \"\"\"\n",
        "    Counts the number of posts in the specified thread.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    session : requests.Session\n",
        "        The session object used for making HTTP requests.\n",
        "    thread : str\n",
        "        The thread to count posts in.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The number of posts in the specified thread.\n",
        "    \"\"\"\n",
        "    page = session.get(thread).content\n",
        "    post_count_path = \"(//div[@class='pagination'])[2]/text()\"\n",
        "    numberOfPosts = html.fromstring(page).xpath(post_count_path)[0]\n",
        "    return int(numberOfPosts[: numberOfPosts.find(\" \")].strip())\n",
        "\n",
        "def get_posts(\n",
        "    session: requests.Session, thread: str, start: int = 0, end: int = -1\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Retrieve posts from a thread.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    session : requests.Session\n",
        "        The session object used for making HTTP requests.\n",
        "    thread : str\n",
        "        The thread to retrieve the posts of.\n",
        "    start : int, optional\n",
        "        The post number to start retrieving from. Default is 0.\n",
        "    end : int, optional\n",
        "        The post number to stop retrieving at. Default is infinity.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[dict]\n",
        "        Each post's data, including post `id`, `number`, `user, `time`, and `content`.\n",
        "    \"\"\"\n",
        "\n",
        "    posts_per_page = 25\n",
        "    post_body_path = \"//div[@class='postbody']\"\n",
        "    post_number_path = \".//span[@class='post-number-bolded']//text()\"\n",
        "    post_user_path = \".//a[@class='username' or @class='username-coloured']/text()\"\n",
        "    post_content_path = \".//div[@class='content']\"\n",
        "    post_timestamp_path = \".//p[@class='author modified']/text()\"\n",
        "    post_id_path = \".//a/@href\"\n",
        "    end = end if end != -1 else count_posts(session, thread)\n",
        "\n",
        "    # identify pages to visit\n",
        "    start_page_id = floor(start / posts_per_page) * posts_per_page\n",
        "    end_page_id = floor(end / posts_per_page) * posts_per_page\n",
        "\n",
        "    # collect on each page key content from posts after current post\n",
        "    posts = []\n",
        "    for page_index in range(start_page_id, (end_page_id + 1), posts_per_page):\n",
        "        page = session.get(f\"{thread}&start={str(page_index)}\").content\n",
        "        for raw_post in html.fromstring(page).xpath(post_body_path):\n",
        "            post_number = int(raw_post.xpath(post_number_path)[0][1:])\n",
        "            if post_number < start or post_number > end:\n",
        "                continue\n",
        "            posts.append({\"number\": post_number})\n",
        "            posts[-1][\"id\"] = raw_post.xpath(post_id_path)[0]\n",
        "            posts[-1][\"id\"] = posts[-1][\"id\"][posts[-1][\"id\"].rfind(\"#\") + 2 :]\n",
        "            posts[-1][\"user\"] = raw_post.xpath(post_user_path)[0]\n",
        "            posts[-1][\"content\"] = raw_post.xpath(post_content_path)[0]\n",
        "            posts[-1][\"content\"] = html.tostring(raw_post.xpath(post_content_path)[0])\n",
        "            posts[-1][\"content\"] = posts[-1][\"content\"].decode(\"UTF-8\").strip()[21:-6]\n",
        "            posts[-1][\"time\"] = raw_post.xpath(post_timestamp_path)[-1]\n",
        "            posts[-1][\"time\"] = posts[-1][\"time\"][\n",
        "                posts[-1][\"time\"].find(\"Â» \") + 2 :\n",
        "            ].strip()\n",
        "            #posts[-1][\"time\"] = dt.strptime(posts[-1][\"time\"], \"%a %b %d, %Y %I:%M %p\")\n",
        "\n",
        "    return posts\n",
        "\n",
        "def extract_youtube_links(post_content: str):\n",
        "    \"Return all links to youtube videos in the post content\"\n",
        "\n",
        "    clean_youtube_links = []\n",
        "    for link in html.fromstring(post_content).xpath(\"//iframe/@src\"):\n",
        "        if \"youtube\" not in link:\n",
        "            continue\n",
        "        video_id = link.split(\"/\")[-1]\n",
        "        clean_youtube_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "    return clean_youtube_links\n",
        "\n",
        "\n",
        "def create_playlist_url(video_links: list[str]):\n",
        "    \"Return a youtube playlist url from a list of video links\"\n",
        "\n",
        "    video_ids = [link.split(\"v=\")[1] for link in video_links]\n",
        "    return f\"http://www.youtube.com/watch_videos?video_ids={','.join(video_ids)}\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    session = requests.Session()\n",
        "    posts = get_posts(session, thread)\n",
        "    youtube_links = []\n",
        "    for post in posts:\n",
        "        if post[\"user\"] != posts[0][\"user\"]:\n",
        "            continue\n",
        "\n",
        "        youtube_links.extend(extract_youtube_links(post[\"content\"]))\n",
        "\n",
        "    playlist_url = create_playlist_url(youtube_links)\n",
        "    final_playlist_url = session.get(playlist_url).url\n",
        "    \n",
        "    print('Playlist URL:')\n",
        "    if playlist_type == 'music':\n",
        "        print(final_playlist_url.replace('www', 'music'))\n",
        "    else:\n",
        "        print(final_playlist_url)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
