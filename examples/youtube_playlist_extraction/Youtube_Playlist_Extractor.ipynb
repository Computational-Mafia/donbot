{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zDjhdUxwTz3"
      },
      "source": [
        "# YouTube Playlist Extractor\n",
        "\n",
        "A lot of threads on mafiascum.net contain links to YouTube videos distributed across multiple posts. Particularly when they share the same purpose or theme, it can be useful to extract these links and compile them into a single playlist for easy viewing or listening.\n",
        "\n",
        "This example demonstrates how to use functions from the [donbot](https://github.com/Computational-Mafia/donbot) module to extract YouTube video links across a thread and compile them into a playlist. By changing the thread URL parameter and maybe adding your account credentials, you can use this example to extract a playlist from any thread on the forum.\n",
        "\n",
        "Stick to the regular videos and long URL if you have any problems -- Youtube Music sometimes rejects videos that regular Youtube accepts. This implementation also splits playlists into 50-song chunks to avoid exceeding the maximum playlist size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8QGiRSQu21v",
        "outputId": "5a210015-bea9-4caf-a4a4-912b7d03d0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playlist URL:\n",
            "http://www.youtube.com/watch_videos?video_ids=ZE2ywCcKkdQ,Cxg816ib59g,JdpQbOIurWE,QExrA3u6Pr4,Fwv2gnCFDOc,9kXun-jTgSE,EKOSQGKn5Cw,xs5i2wrR1fM,EUbXEQt8O2o,x2RV8O_UEvQ,1jQeYAhcSHo,Mf0lisBZQP8,QHum-uAr2Dk,XEtRzDYYBuY,RdJOSfgKC9s,rUmV-MorIKc,pMqOMFW3Gt8,Yr1XtIMOjy0,gfIogMO2dng,3G2o0i1zlw8,JXWkKO4eplY,T3yFMygkc_E,wPAjvd0Co-Q,P2dDmqZonks,eYCSgyxsPS8,_G-4SqeibHk,Kuq3tsmBS88,aHUVqV5CO6w,O6MD-BzhM5M,zJE1HoHabMw,fu3Nn2TI2rc,IDdSk5f3cYQ,mFRNUzHYFWw,f_UFDuUkguo,lC6BnkM4gmc,zAoCaXwu1bg,4eaJ2aEqymo,ikhvTVCjOgs,W2bc25X0E68,dLxPIOxgkM0,TusmIYX22jM,G3IOBsR7yGM,z195KENb5Ik,COl55r9tbaA,tOoVwhHUq_M,0LMnuVRk_0c,plUePWTg7E0,G2d37oySCfk,LQboZNoMd0c,kGrG1gKG-TE\n",
            "Playlist URL:\n",
            "http://www.youtube.com/watch_videos?video_ids=Gzz7at1p4rs,ApxiLIjRzM0,gTOm9vEfSmU,FkSFBcjOKHY,HKmYRsnMsOk,VDmCjHJqsj0,BDhJU_cNCZE,m5ra-w1xct8,xEJz2zsusRE,NscuHPnHqbs,6bYKZbWxKoQ,4V0Wr6j9wc8,2twY8YQYDBE,yILthll0pzU,8fcy2X06VH4,c4HovBdrsYM,ZIgtEW8jOt4,ZAZgXyLZJKE,CPGRtlZLiSI,LChtBpTjvTY,JP2728BtJ34,9cFzKPdImjo,QeJohNeVIjI,T-fKCnPwvm8,sOolS_FvOJc,bTxXVhdmdZc,AM2GopRUopo,aCu93MKq7ec,8O7VTw1E3b4,luScN4B2Xqc,2FN2EfesYR0,whYzJIm3qbA,Kj-WdkDblSU,Gcj9-iF_lTw,U6CfCg-9-mU,qUWE2aR07Jc,skX4FftyT1s,dRHetRTOD1Q,Vj3t-tYvNL0,dYOSYDBJyZg,aZl0UcTYfeY,JkpEEcWTahs,8nYhNlj8XPI,Ylll7UiH7PA,OujmHVSihgk,vWgs9DqYQoc,WKnVaDwUg5s,_hhbk9CsfyE,FtEsqspxONg,EGXPAoyP_cg\n",
            "Playlist URL:\n",
            "http://www.youtube.com/watch_videos?video_ids=GWkALXa2vn4,nn1y5IPjiOo,oS4CpLf5W_A,fj04rzn-Cxs,8O7VTw1E3b4,PSm0ay2xizI,b9Mk_Keheow,S8Tqjw7eHLY,STVktGM-MG8,4IFriJZFhnk,8PijzIDM-n4,lkk6m14htzw,drDgZZNw2-Q,VjqimqlaeZQ,TDTeUimEyUA,l42KfnI0pR8,RFWlQ69-J7o,nDbeqj-1XOo,e8i1T6uly9A,SNRJ2v9IEfU,60hZ58TZj9A,AIAQDlEXvvQ,n51MgREfiMQ,Vapkdzq3Ja4,zuatOQOTVNw,FsyondTsrqM,9e4heRDhJ94,uCR34pOOQMg,mrk29HQfv7Q,lcQ853ibg08,YLp2cW7ICCU,Z4VtBr-5K10,9p3OuktD664,qhPGbr51jfc,shSWLmhdux4,75AMKEZS80Y,8Cya2MV_GRI,Ise3eGYFWHA,hrXBoAnXCLE,JlwcQR5HHck,1Hsj3oYhsbk,FKwVFWwA_x8,h59YyEFKIwg,1BY1Vrkdqmo,q4nKCOq2EI0,uJxaUi9f5vo,eX1pu8JQfNs,JeynBhk4oso,jIihdBiNcuc,EUfSzjzIi40\n",
            "Playlist URL:\n",
            "http://www.youtube.com/watch_videos?video_ids=RxSw68WOBWo,LRouzANEgE4,s59hEBtRlwk,bRt5z880CFY,h1rRmUIiJvo,X5Y1TaT0mRQ,sR-DZ2Mpf1w,Ymplapgd63o,RP0_8J7uxhs,WEsibVKPNA0,hGUJcqxbRLo,9p3OuktD664,ytM-D1hGuFQ,6bx1ieTDt2g\n"
          ]
        }
      ],
      "source": [
        "# @markdown ## Provide a thread url, playlist type, and url structure. Press the play button the left to generate!\n",
        "thread = \"https://forum.mafiascum.net/viewtopic.php?t=91822\"  # @param {type:\"string\"}\n",
        "playlist_type = \"regular videos\"  # @param [\"music\", \"regular videos\"]\n",
        "try_to_shorten_playlist_url = False  # @param {type:\"boolean\"}\n",
        "\n",
        "import requests\n",
        "from lxml import html\n",
        "from lxml.html import HtmlElement\n",
        "from math import floor\n",
        "\n",
        "\n",
        "def count_posts(thread_html: HtmlElement) -> int:\n",
        "    \"\"\"\n",
        "    Counts the number of posts in the specified thread.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    thread_html : HtmlElement\n",
        "        The HTML of a page from the thread to count posts in.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The number of posts in the specified thread.\n",
        "    \"\"\"\n",
        "    post_count_path = \"//div[@class='pagination']/text()\"\n",
        "    post_count_element = next(\n",
        "        el for el in thread_html.xpath(post_count_path) if el.strip()\n",
        "    )\n",
        "    return int(\"\".join([c for c in post_count_element if c.isdigit()]))\n",
        "\n",
        "\n",
        "def get_post(post_html: HtmlElement) -> dict:  # sourcery skip: merge-dict-assign\n",
        "    \"\"\"\n",
        "    Extracts the data of a post from the post HTML.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    post_html : HtmlElement\n",
        "        The HTML of a post.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        The post's data, including post `id`, `number`, `user, `time`, and `content`.\n",
        "    \"\"\"\n",
        "    post_number_path = \".//span[@class='post-number-bolded']//text()\"\n",
        "    post_user_path = \".//a[@class='username' or @class='username-coloured']/text()\"\n",
        "    post_user_id_path = \".//a[@class='username' or @class='username-coloured']/@href\"\n",
        "    post_content_path = \".//div[@class='content']\"\n",
        "    post_timestamp_path = \".//p[@class='author modified']/text()\"\n",
        "    post_id_path = \".//a/@href\"\n",
        "\n",
        "    post = {}\n",
        "    post[\"number\"] = int(post_html.xpath(post_number_path)[0][1:])\n",
        "    post[\"id\"] = post_html.xpath(post_id_path)[0]\n",
        "    post[\"id\"] = post[\"id\"][post[\"id\"].rfind(\"#\") + 2 :]\n",
        "    post[\"user\"] = post_html.xpath(post_user_path)[0]\n",
        "    post[\"user_id\"] = post_html.xpath(post_user_id_path)[0]\n",
        "    post[\"user_id\"] = post[\"user_id\"][post[\"user_id\"].rfind(\"=\") + 1 :]\n",
        "    post[\"content\"] = html.tostring(post_html.xpath(post_content_path)[0])\n",
        "    post[\"content\"] = post[\"content\"].decode(\"UTF-8\").strip()[21:-6]\n",
        "    post[\"time\"] = post_html.xpath(post_timestamp_path)[-1]\n",
        "    post[\"time\"] = post[\"time\"][post[\"time\"].find(\"Â» \") + 2 :].strip()\n",
        "    return post\n",
        "\n",
        "\n",
        "def get_posts(\n",
        "    thread_page_html: HtmlElement, start: int = 0, end: int | float = -1\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Retrieve posts from a thread.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    thread_page_html : HtmlElement\n",
        "        The HTML of a page from the thread to retrieve posts from.\n",
        "    start : int\n",
        "        Lowest post number to retrieve.\n",
        "    end : int, optional\n",
        "        Highest post number to retrieve.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[dict]\n",
        "        Each post's data, including post `id`, `number`, `user, `time`, and `content`.\n",
        "    \"\"\"\n",
        "    posts = []\n",
        "    end = end if end != -1 else float(\"inf\")\n",
        "    for raw_post in thread_page_html.xpath(\"//div[@class='postbody']\"):\n",
        "        post = get_post(raw_post)\n",
        "        if post[\"number\"] >= start and post[\"number\"] <= end:\n",
        "            posts.append(post)\n",
        "    return posts\n",
        "\n",
        "\n",
        "def get_thread_page_urls(\n",
        "    thread: str, thread_page_html: HtmlElement, start: int = 0, end: int = -1\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Get the URLs of the pages of a thread.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    thread : str\n",
        "        The URL of the thread.\n",
        "    thread_page_html : HtmlElement\n",
        "        The HTML of a page from the thread.\n",
        "    end : int\n",
        "        The number of pages to retrieve.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[str]\n",
        "        The URLs of the pages of the thread.\n",
        "    \"\"\"\n",
        "    end = end if end != -1 else count_posts(thread_page_html)\n",
        "\n",
        "    posts_per_page = 25\n",
        "    start_page_id = floor(start / posts_per_page) * posts_per_page\n",
        "    end_page_id = floor(end / posts_per_page) * posts_per_page\n",
        "\n",
        "    return [\n",
        "        f\"{thread}&start={str(page_id)}\"\n",
        "        for page_id in range(start_page_id, end_page_id + 1, posts_per_page)\n",
        "    ]\n",
        "\n",
        "\n",
        "def extract_youtube_links(post_content: str):\n",
        "    \"Return all links to youtube videos in the post content\"\n",
        "\n",
        "    clean_youtube_links = []\n",
        "    for link_path in [\"//iframe/@src\", \"//a/@href\"]:\n",
        "        for link in html.fromstring(post_content).xpath(link_path):\n",
        "            if \"list\" in link:\n",
        "                continue\n",
        "            if \"youtube\" not in link and \"youtu.be\" not in link:\n",
        "                continue\n",
        "            video_id = link.split(\"/\")[-1]\n",
        "            clean_youtube_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "    return clean_youtube_links\n",
        "\n",
        "\n",
        "def create_playlist_url(video_links: list[str]):\n",
        "    \"Return a youtube playlist url from a list of video links\"\n",
        "    \n",
        "    video_ids = []\n",
        "    for link in video_links:\n",
        "        video_id = link.split(\"v=\")[1]\n",
        "        if video_id not in video_ids:\n",
        "            video_ids.append(video_id)\n",
        "    return f\"http://www.youtube.com/watch_videos?video_ids={','.join(video_ids)}\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    session = requests.Session()\n",
        "    thread_html = html.fromstring(session.get(thread).content)\n",
        "    thread_urls = get_thread_page_urls(thread, thread_html)\n",
        "\n",
        "    posts = []\n",
        "    for thread_url in thread_urls:\n",
        "        thread_page_html = html.fromstring(session.get(thread_url).content)\n",
        "        posts.extend(get_posts(thread_page_html))\n",
        "    \n",
        "    first_user_contents = [post[\"content\"] for post in posts if post[\"user\"] == posts[0][\"user\"]]\n",
        "    youtube_links = sum(\n",
        "        (extract_youtube_links(content) for content in first_user_contents), []\n",
        "    )\n",
        "    for i in range(0, len(youtube_links), 50):\n",
        "        youtube_links_subset = youtube_links[i:min(i + 50, len(youtube_links))]\n",
        "        playlist_url = create_playlist_url(youtube_links_subset)\n",
        "        if try_to_shorten_playlist_url:\n",
        "            playlist_url = session.get(playlist_url).url\n",
        "\n",
        "        print('Playlist URL:')\n",
        "        if playlist_type == 'music':\n",
        "            print(playlist_url.replace('www', 'music'))\n",
        "        else:\n",
        "            print(playlist_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
